{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c441f9d2",
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9fe9eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90dffac",
   "metadata": {},
   "source": [
    "## Image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "dc0ebd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6e3efaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(paths):\n",
    "    images = [Image.open(p) for p in paths]\n",
    "    classes = [p.parent.name for p in paths]\n",
    "    return (images, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b9646439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>],\n",
       " ['5', '9', '4'])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadImages([\n",
    "    path/\"training\"/\"5\"/\"0.png\",\n",
    "    path/\"training\"/\"9\"/\"10003.png\",\n",
    "    path/\"testing\"/\"4\"/\"1059.png\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9cfb2b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, pathlib.WindowsPath)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def allImages(path):\n",
    "    return list(path.glob(\"**/*.png\"))\n",
    "\n",
    "testImages = allImages(path)\n",
    "assert len(testImages) > 0\n",
    "for image in testImages: assert image.name.endswith(\".png\") \n",
    "len(testImages), type(testImages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d796435",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "19f19b55",
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, imageSize, categoryCount):\n",
    "        self.learningEnabled = True\n",
    "        hiddenSize = imageSize[0] * imageSize[1]\n",
    "        self.w1 = self.__initParams(imageSize[0] * imageSize[1], hiddenSize)\n",
    "        self.b1 = self.__initParams(hiddenSize)\n",
    "        \n",
    "        self.w2 = self.__initParams(hiddenSize, categoryCount)\n",
    "        self.b2 = self.__initParams(categoryCount)\n",
    "        \n",
    "        self.params = [self.w1, self.b1, self.w2, self.b2]\n",
    "        \n",
    "    def applyModel(self, batch):\n",
    "        hiddenLayer1 = F.relu(batch@self.w1 + self.b1)\n",
    "        return hiddenLayer1@self.w2 + self.b2\n",
    "    \n",
    "    def fit(self, lr):\n",
    "        if not self.learningEnabled:\n",
    "            raise Exception(\"Learning is diabled\")\n",
    "            \n",
    "        for p in self.params:\n",
    "            p.data -= p.grad.data * lr\n",
    "            p.grad.zero_()\n",
    "    \n",
    "    def __initParams(self, *size):\n",
    "        return (torch.rand(size) * 0.01).requires_grad_()\n",
    "    \n",
    "    def disableLearning(self):\n",
    "        self.learningEnabled = False\n",
    "        for p in self.params:\n",
    "            p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc7ca4",
   "metadata": {},
   "source": [
    "## Learning preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf6c0c6",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "60e927a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(predictedProbabilities, targetProbabilities):\n",
    "    return torch.square(targetProbabilities - predictedProbabilities).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5c06a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a8c14040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6067), tensor(0.4594))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = lossFunction(\n",
    "    tensor([\n",
    "        [0.7, 0.4, 0.9], # wrong prediction\n",
    "    ]),\n",
    "    tensor([\n",
    "        [0, 0, 1],\n",
    "    ]).float()\n",
    ")\n",
    "test2 = lossFunction(\n",
    "    tensor([\n",
    "        [0.6, 0.3, 0.9], # less wrong prediction\n",
    "    ]),\n",
    "    tensor([\n",
    "        [0, 0, 1],\n",
    "    ]).float()  \n",
    ")\n",
    "test1, test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a26fb",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "39db786c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateAccuracy(targetPredictions, predictions):\n",
    "    border = 0.5\n",
    "    return ((predictions > border) == (targetPredictions > border)).all(dim=1).float().mean()\n",
    "\n",
    "calculateAccuracy(\n",
    "    tensor([\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0]\n",
    "    ]),\n",
    "    tensor([\n",
    "        [0.7, 0.4, 0.9], # wrong prediction\n",
    "        [0.2, 0.61, 0.48], # correct prediction\n",
    "        [0.2, 0.1, 0.3] # wrong prediction\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f9178e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLoader:\n",
    "    def __init__(self, images, batchSize):\n",
    "        self.images = images.copy()\n",
    "        random.shuffle(self.images)\n",
    "        self.batchSize = batchSize\n",
    "        self.nextBatch = 0 \n",
    "    def nextBatch(self):\n",
    "        batchStartIndex = min(self.batchSize * self.nextBatch, len(self.images))\n",
    "        batchEndIndex = min(startBatchFrom + self.batchSize, len(self.images))\n",
    "        if batchStartIndex == batchEndIndex:\n",
    "            return None\n",
    "        else:\n",
    "            return self.images[batchStartIndex:batchEndIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3b469358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLoader:\n",
    "    def __init__(self, items, batchSize):\n",
    "        self.items = items.copy()\n",
    "        random.shuffle(self.items)\n",
    "        self.batchSize = batchSize\n",
    "        self.nextBatch = 0 \n",
    "    def getNextBatch(self):\n",
    "        batchStartIndex = min(self.batchSize * self.nextBatch, len(self.items))\n",
    "        batchEndIndex = min(batchStartIndex + self.batchSize, len(self.items))\n",
    "        if batchStartIndex == batchEndIndex:\n",
    "            return None\n",
    "        else:\n",
    "            self.nextBatch += 1\n",
    "            return self.items[batchStartIndex:batchEndIndex]\n",
    "       \n",
    "    \n",
    "testItems = [1, 2, 3, 4, 5, 6, 7]\n",
    "testLoader = BatchLoader(testItems, 4)\n",
    "receivedItems = testLoader.getNextBatch() + testLoader.getNextBatch()\n",
    "receivedItems.sort()\n",
    "assert testItems == receivedItems, \"received aren't the same as tests \" + receivedItems\n",
    "assert testLoader.getNextBatch() == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6bf6dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBatchOfImages(paths):\n",
    "    images = [tensor(Image.open(p)).view(-1) for p in paths]\n",
    "    return torch.stack(images).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fc14d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBatch(paths):\n",
    "    images = loadBatchOfImages(paths)\n",
    "    classes = [p.parent.name for p in paths]\n",
    "    return (images, classes)\n",
    "    \n",
    "testBatchLoader = BatchLoader(allImages(path/\"training\"), 100)\n",
    "trainingImages, trainingClasses = loadBatch(testBatchLoader.getNextBatch())\n",
    "assert len(trainingImages) == len(trainingClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "82dc2dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numberToPrediction(number):\n",
    "    return [1.0 if i == number else 0.0 for i in range(10)]\n",
    "\n",
    "def targetPredictions(classes):\n",
    "    return tensor([numberToPrediction(int(c)) for c in classes])\n",
    "\n",
    "targetPredictions([\"0\", \"5\", \"9\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd3e4de",
   "metadata": {},
   "source": [
    "### The learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3f7e403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions\n",
      "tensor([[0.9257, 0.9209, 0.9228, 0.9303, 0.9217, 0.9241, 0.9201, 0.9280, 0.9211, 0.9252],\n",
      "        [0.7860, 0.7796, 0.7831, 0.7922, 0.7814, 0.7841, 0.7794, 0.7889, 0.7797, 0.7849],\n",
      "        [0.9251, 0.9201, 0.9220, 0.9298, 0.9207, 0.9238, 0.9196, 0.9274, 0.9203, 0.9241],\n",
      "        [0.8421, 0.8364, 0.8390, 0.8489, 0.8378, 0.8408, 0.8357, 0.8458, 0.8368, 0.8413],\n",
      "        [0.8811, 0.8756, 0.8777, 0.8872, 0.8765, 0.8797, 0.8745, 0.8841, 0.8752, 0.8800],\n",
      "        [0.8248, 0.8185, 0.8210, 0.8313, 0.8196, 0.8225, 0.8178, 0.8275, 0.8184, 0.8234],\n",
      "        [0.8837, 0.8784, 0.8801, 0.8897, 0.8791, 0.8823, 0.8775, 0.8866, 0.8784, 0.8833],\n",
      "        [0.8402, 0.8340, 0.8372, 0.8466, 0.8353, 0.8383, 0.8331, 0.8435, 0.8343, 0.8390],\n",
      "        [0.9211, 0.9162, 0.9182, 0.9260, 0.9169, 0.9197, 0.9153, 0.9237, 0.9163, 0.9202],\n",
      "        [0.9677, 0.9648, 0.9658, 0.9706, 0.9652, 0.9671, 0.9643, 0.9693, 0.9650, 0.9674]], grad_fn=<SigmoidBackward0>)\n",
      "targets\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validateOneBatch(model, batch):\n",
    "    images, classes = loadBatch(batch)\n",
    "    predictions = model.applyModel(images).sigmoid()\n",
    "    print(\"predictions\")\n",
    "    print(predictions)\n",
    "    target = targetPredictions(classes)\n",
    "    print(\"targets\")\n",
    "    print(target)\n",
    "    return calculateAccuracy(target, predictions)\n",
    "\n",
    "validateOneBatch(Model((28,28), 10), allImages(path/\"testing/4\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b5cc7503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validateEpoach(model, validationSet, batchSize):\n",
    "    batchLoader = BatchLoader(validationSet, batchSize)\n",
    "    batch = batchLoader.getNextBatch()\n",
    "    accuracies = []\n",
    "    while batch != None:\n",
    "        accuracies.append(validateOneBatch(model, batch))\n",
    "        batch = batchLoader.getNextBatch()\n",
    "    return round(torch.stack(accuracies).mean().item(), 4)\n",
    "\n",
    "validateEpoach(Model((28,28), 10), allImages(path/\"testing\"), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "54002729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1406452655792236\n"
     ]
    }
   ],
   "source": [
    "def fitOneBatch(model, batch, lr):\n",
    "    traingingImages, trainingClasses = loadBatch(batch)\n",
    "    predictions = model.applyModel(traingingImages).sigmoid()\n",
    "    #print(\"predictions \" + str(predictions))\n",
    "    target = targetPredictions(trainingClasses)\n",
    "    #print(\"target \" + str(target))\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    loss = criterion(predictions,target)\n",
    "    loss.backward()\n",
    "    #print(\"Grad w1 \" + str(model.w1.grad.mean()) + \", b1 \" + str(model.b1.grad.mean()))\n",
    "    model.fit(lr)\n",
    "    print(\"Loss: \" + str(loss.item()))\n",
    "\n",
    "fitOneBatch(Model((28, 28), 10), allImages(path/\"training/6\")[:10], 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "047fea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1336984634399414\n",
      "Loss: 1.0321985483169556\n",
      "Loss: 0.7815778851509094\n",
      "Loss: 0.726283848285675\n",
      "Loss: 0.7160937786102295\n",
      "Loss: 0.7106762528419495\n",
      "Accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "def trainEpoach(model, trainingSet, validationSet,  batchSize, lr):\n",
    "    batchLoader = BatchLoader(trainingSet, batchSize)\n",
    "    batch = batchLoader.getNextBatch()\n",
    "    while batch != None:\n",
    "        fitOneBatch(model, batch, lr)\n",
    "        batch = batchLoader.getNextBatch()\n",
    "    accuracy = validateEpoach(model, validationSet, batchSize)\n",
    "    print(\"Accuracy \" + str(accuracy))\n",
    "    \n",
    "model = Model((28, 28), 10)    \n",
    "trainEpoach(model, allImages(path/\"training\"), allImages(path/\"testing\"), 10000, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b39bf018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1328374147415161\n",
      "Loss: 0.8830285668373108\n",
      "Loss: 0.7001266479492188\n",
      "Loss: 0.6992723941802979\n",
      "Loss: 0.6984172463417053\n",
      "Loss: 0.6980047821998596\n",
      "predictions\n",
      "tensor([[0.0474, 0.0468, 0.0481,  ..., 0.0457, 0.0460, 0.0444],\n",
      "        [0.0015, 0.0015, 0.0016,  ..., 0.0014, 0.0014, 0.0013],\n",
      "        [0.0025, 0.0024, 0.0026,  ..., 0.0023, 0.0024, 0.0022],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0112, 0.0109, 0.0115,  ..., 0.0106, 0.0107, 0.0102],\n",
      "        [0.0024, 0.0022, 0.0025,  ..., 0.0022, 0.0022, 0.0021]], grad_fn=<SigmoidBackward0>)\n",
      "targets\n",
      "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Accuracy 0.0\n",
      "Loss: 0.6975518465042114\n",
      "Loss: 0.6973915696144104\n",
      "Loss: 0.6970617175102234\n",
      "Loss: 0.6968950033187866\n",
      "Loss: 0.6967011094093323\n",
      "Loss: 0.6965218186378479\n",
      "predictions\n",
      "tensor([[0.0277, 0.0310, 0.0283,  ..., 0.0278, 0.0271, 0.0268],\n",
      "        [0.0018, 0.0022, 0.0019,  ..., 0.0018, 0.0018, 0.0017],\n",
      "        [0.0023, 0.0027, 0.0024,  ..., 0.0023, 0.0022, 0.0021],\n",
      "        ...,\n",
      "        [0.0010, 0.0013, 0.0011,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        [0.0078, 0.0090, 0.0081,  ..., 0.0078, 0.0075, 0.0074],\n",
      "        [0.0064, 0.0074, 0.0066,  ..., 0.0064, 0.0062, 0.0061]], grad_fn=<SigmoidBackward0>)\n",
      "targets\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.]])\n",
      "Accuracy 0.0\n",
      "Loss: 0.6964547634124756\n",
      "Loss: 0.6964312791824341\n",
      "Loss: 0.6963121891021729\n",
      "Loss: 0.6962754726409912\n",
      "Loss: 0.6962454915046692\n",
      "Loss: 0.6961206197738647\n",
      "predictions\n",
      "tensor([[0.0057, 0.0073, 0.0059,  ..., 0.0059, 0.0056, 0.0056],\n",
      "        [0.0007, 0.0009, 0.0007,  ..., 0.0007, 0.0007, 0.0007],\n",
      "        [0.0022, 0.0030, 0.0023,  ..., 0.0023, 0.0022, 0.0022],\n",
      "        ...,\n",
      "        [0.0053, 0.0069, 0.0056,  ..., 0.0055, 0.0052, 0.0052],\n",
      "        [0.0021, 0.0028, 0.0022,  ..., 0.0022, 0.0021, 0.0020],\n",
      "        [0.0046, 0.0061, 0.0048,  ..., 0.0048, 0.0045, 0.0045]], grad_fn=<SigmoidBackward0>)\n",
      "targets\n",
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.]])\n",
      "Accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "model = Model((28, 28), 10)\n",
    "for e in range(1, 4):\n",
    "    trainEpoach(model, allImages(path/\"training\"), allImages(path/\"testing\"), 10000, 2. / e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5e08e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.disableLearning()\n",
    "with open('model.pkl', 'wb') as output:\n",
    "    pickle.dump(model, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "abeee455",
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def loadModel(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2a0a1edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0030, 0.0050, 0.0032, 0.0033, 0.0035, 0.0033, 0.0033, 0.0038, 0.0031, 0.0035]]),\n",
       " tensor(0.0993))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel = loadModel('model.pkl')\n",
    "testClassificationResult = testModel.applyModel(loadBatchOfImages([path/\"testing\"/\"4\"/\"1059.png\"])).sigmoid()\n",
    "testMSE = mse(targetPredictions([\"4\"]), testClassificationResult)\n",
    "testClassificationResult, testMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cc7d4b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validateOneBatch(testModel, allImages(path/\"testing\"/\"4\")[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4ccf3f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 3 functions to model.py\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "import ipynbname\n",
    "\n",
    "notebook_path = ipynbname.path() \n",
    "output_file = \"model.py\"\n",
    "\n",
    "# Load the notebook\n",
    "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Extract code from cells with the \"export\" tag\n",
    "exported_code = []\n",
    "for cell in notebook.cells:\n",
    "    if cell.cell_type == \"code\" and \"tags\" in cell.metadata:\n",
    "        if \"export\" in cell.metadata.tags:\n",
    "            exported_code.append(cell.source)\n",
    "\n",
    "# Write the extracted code to a .py file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(exported_code))\n",
    "\n",
    "print(f\"Exported {len(exported_code)} functions to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce98db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:fastbook] *",
   "language": "python",
   "name": "conda-env-fastbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
