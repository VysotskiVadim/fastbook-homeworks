{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c441f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe9eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90dffac",
   "metadata": {},
   "source": [
    "## Image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0ebd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3efaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>],\n",
       " ['5', '9'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadImages(paths):\n",
    "    images = [Image.open(p) for p in paths]\n",
    "    classes = [p.parent.name for p in paths]\n",
    "    return (images, classes)\n",
    "    \n",
    "loadImages([\n",
    "    path/\"training\"/\"5\"/\"0.png\",\n",
    "    path/\"training\"/\"9\"/\"10003.png\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfb2b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, pathlib.WindowsPath)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def allImages(path):\n",
    "    return list(path.glob(\"**/*.png\"))\n",
    "\n",
    "testImages = allImages(path)\n",
    "assert len(testImages) > 0\n",
    "for image in testImages: assert image.name.endswith(\".png\") \n",
    "len(testImages), type(testImages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d796435",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19f19b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, imageSize, categoryCount):\n",
    "        self.w1 = self.__initParams(imageSize[0] * imageSize[1], categoryCount)\n",
    "        self.b1 = self.__initParams(categoryCount)\n",
    "        self.params = [self.w1, self.b1]\n",
    "        \n",
    "    def applyModel(self, batch):\n",
    "        return batch@self.w1 + self.b1\n",
    "    \n",
    "    def fit(self, lr):\n",
    "        for p in self.params:\n",
    "            #print(\"adopting model by \" + str(p.grad))\n",
    "            p.data -= p.grad.data * lr\n",
    "            p.grad = None\n",
    "    \n",
    "    def __initParams(self, *size):\n",
    "        return torch.rand(size).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc7ca4",
   "metadata": {},
   "source": [
    "## Learning preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e927a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1367), tensor(0.1000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(targetProbabilities, predictedProbabilities):\n",
    "    return torch.square(targetProbabilities - predictedProbabilities).mean()\n",
    "\n",
    "testTargets = tensor([1, 0, 1])\n",
    "test1 = mse(testTargets, tensor([0.9, 0.2, 0.4]))\n",
    "test2 = mse(testTargets, tensor([0.9, 0.2, 0.5]))\n",
    "test1, test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98754fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0180, 0.2689, 0.7311, 0.9820])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
    "\n",
    "sigmoid(tensor([-4, -1, 1, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3bb878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0841), tensor(0.0249))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse_loss(targetProbabilities, predictions):\n",
    "    return mse(targetProbabilities, sigmoid(predictions))\n",
    "    \n",
    "test1 = mse_loss(tensor([1, 0, 1]), tensor([10, -3, 0]))\n",
    "test2 = mse_loss(tensor([1, 0, 1]), tensor([10, -3, 1]))\n",
    "test1, test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39db786c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateAccuracy(targetPredictions, predictions):\n",
    "    border = 0.5\n",
    "    return ((predictions > border) == (targetPredictions > border)).float().mean()\n",
    "\n",
    "calculateAccuracy(tensor([1, 0, 1]), tensor([0.2, 0, 0.61]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9178e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLoader:\n",
    "    def __init__(self, images, batchSize):\n",
    "        self.images = images.copy()\n",
    "        random.shuffle(self.images)\n",
    "        self.batchSize = batchSize\n",
    "        self.nextBatch = 0 \n",
    "    def nextBatch(self):\n",
    "        batchStartIndex = min(self.batchSize * self.nextBatch, len(self.images))\n",
    "        batchEndIndex = min(startBatchFrom + self.batchSize, len(self.images))\n",
    "        if batchStartIndex == batchEndIndex:\n",
    "            return None\n",
    "        else:\n",
    "            return self.images[batchStartIndex:batchEndIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b469358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLoader:\n",
    "    def __init__(self, items, batchSize):\n",
    "        self.items = items.copy()\n",
    "        random.shuffle(self.items)\n",
    "        self.batchSize = batchSize\n",
    "        self.nextBatch = 0 \n",
    "    def getNextBatch(self):\n",
    "        batchStartIndex = min(self.batchSize * self.nextBatch, len(self.items))\n",
    "        batchEndIndex = min(batchStartIndex + self.batchSize, len(self.items))\n",
    "        if batchStartIndex == batchEndIndex:\n",
    "            return None\n",
    "        else:\n",
    "            self.nextBatch += 1\n",
    "            return self.items[batchStartIndex:batchEndIndex]\n",
    "       \n",
    "    \n",
    "testItems = [1, 2, 3, 4, 5, 6, 7]\n",
    "testLoader = BatchLoader(testItems, 4)\n",
    "receivedItems = testLoader.getNextBatch() + testLoader.getNextBatch()\n",
    "receivedItems.sort()\n",
    "assert testItems == receivedItems, \"received aren't the same as tests \" + receivedItems\n",
    "assert testLoader.getNextBatch() == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc14d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainingBatch(paths):\n",
    "    images = [tensor(Image.open(p)).view(-1) for p in paths]\n",
    "    classes = [p.parent.name for p in paths]\n",
    "    return (torch.stack(images).float()/255, classes)\n",
    "    \n",
    "testBatchLoader = BatchLoader(allImages(path/\"training\"), 100)\n",
    "trainingImages, trainingClasses = loadTrainingBatch(testBatchLoader.getNextBatch())\n",
    "assert len(trainingImages) == len(trainingClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82dc2dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numberToPrediction(number):\n",
    "    return [1 if i == number else 0 for i in range(10)]\n",
    "\n",
    "def targetPredictions(classes):\n",
    "    return tensor([numberToPrediction(int(c)) for c in classes])\n",
    "\n",
    "targetPredictions([\"0\", \"5\", \"9\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd3e4de",
   "metadata": {},
   "source": [
    "### The learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54002729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient\n",
      "tensor(3.6290e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.5411e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(8.5717e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.7580e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999165534973\n",
      "gradient\n",
      "tensor(4.2144e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(7.3416e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.8346e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(3.3813e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.0172e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(7.6641e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(8.8585e-12)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(3.3165e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(8.6880e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(6.3317e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.2589e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(7.2077e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(8.5502e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.0645e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(7.5816e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999997973442078\n",
      "gradient\n",
      "tensor(1.2895e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.8178e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(3.6724e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(8.8963e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.1991e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(9.8034e-12)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.0286e-09)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999996185302734\n",
      "gradient\n",
      "tensor(6.8873e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.5721e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.6459e-12)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(6.4852e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(5.7149e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.1734e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.3669e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(5.8777e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.0644e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.1500e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(8.5321e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(4.1301e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.5245e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.1561e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.8315e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.7048e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(4.6824e-12)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.0005e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.2041e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.9211e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.7845e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(3.0709e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(3.4159e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(7.1635e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.1482e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(2.1949e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.3767e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.4454e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.0809e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(5.2475e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(3.3669e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.6837e-10)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(1.1707e-11)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n",
      "gradient\n",
      "tensor(4.4973e-12)\n",
      "params\n",
      "tensor(0.5005, grad_fn=<MeanBackward0>)\n",
      "Loss: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "def performEpoach(model, trainingSet, batchSize, lr):\n",
    "    batchLoader = BatchLoader(trainingSet, batchSize)\n",
    "    batch = batchLoader.getNextBatch()\n",
    "    while batch != None:\n",
    "        traingingImages, trainingClasses = loadTrainingBatch(batch)\n",
    "        predictions = sigmoid(model.applyModel(traingingImages))\n",
    "        target = targetPredictions(trainingClasses)\n",
    "        loss = mse(target, predictions)\n",
    "        loss.backward()\n",
    "        print(\"gradient\")\n",
    "        print(model.w1.grad.mean())\n",
    "        print(\"params\")\n",
    "        print(model.w1.mean())\n",
    "        model.fit(lr)\n",
    "        #accuracy = calculateAccuracy(target, predictions)\n",
    "        #print(\"Target: \" + str(target))\n",
    "        #print(\"Predicted: \" + str(predictions))\n",
    "        print(\"Loss: \" + str(loss.item()))\n",
    "        #print(\"Accuracy: \" + str(accuracy))\n",
    "        batch = batchLoader.getNextBatch()\n",
    "    \n",
    "model = Model((28, 28), 10)    \n",
    "performEpoach(model, allImages(path/\"training\"), 1000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bf018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastbook] *",
   "language": "python",
   "name": "conda-env-fastbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
